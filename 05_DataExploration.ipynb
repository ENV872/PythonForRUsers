{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LESSON OBJECTIVES\n",
    "1. Set up a data analysis session in Jupyter\n",
    "2. Import and explore datasets in Python\n",
    "3. Apply data exploration skills to a real-world example dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST PRACTICES FOR PYTHON/JUPYTER\n",
    "\n",
    "In many situations in data analytics, you may be expected to work from multiple computers or share projects among multiple users. A few general best practices will avoid common pitfalls related to collaborative work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative paths in Jupyter notebooks.\n",
    "\n",
    "Jupyter notebooks can use absolute or relative paths, but relative paths are more robust and should be used where possible. Relative paths will be relative to where the Jupyter notebook lives and OS commands can navigate up or down the directory structure.\n",
    "\n",
    "#### Listing contents of folders using OS commands followed by `!`. \n",
    "\n",
    "OS-specific commands can be called within Jupyter by preceding them with a \"`!`\". For example, in Windows you can list the contents of the folder containing the script you are running using \"`! dir`\". On unix machines, this would be \"`! ls`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the contents of the current directory\n",
    "!dir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the contents of the data sub directory \n",
    "!dir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the contents of the directory containing the current notebook\n",
    "!dir .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigating folders using Python's built-in `os` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the os module\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a variable holding the current working directory\n",
    "projectDir = os.getcwd()\n",
    "#Display the current working directory\n",
    "print(projectDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the directory to the data folder\n",
    "os.chdir('data')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go back to the current working directory\n",
    "os.chdir(projectDir)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your packages\n",
    "As in R, packages should be loaded early in the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Import pandas, refering to it as \"pd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import your data\n",
    "The easiest way to import CSV data for data analysis is using Panda's [`read_csv()` function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) which reads data directly into a Pandas dataframe object.\n",
    "\n",
    "As in R, we supply the path to the CSV file, using relative path conventions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_USGS = pd.read_csv('./data/Raw/USGS_Site02085000_Flow_Raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE YOUR DATASET\n",
    "Take a moment to read through the README file associated with the USGS dataset on discharge at the Eno River. Where can you find this file? How does the placement and information found in this file relate to the best practices for reproducible data analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View all records\n",
    "df_USGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing properties of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm the data type -- R: class(df_USGS)\n",
    "type(df_USGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the column names -- R: colnames(df_USGS)\n",
    "df_USGS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns -- R: colnames(df_USGS) <- c(...)\n",
    "df_USGS.columns = (\"agency_cd\", \"site_no\", \"datetime\", \n",
    "                   \"discharge_max\", \"discharge_max_approval\", \n",
    "                   \"discharge_min\", \"discharge_min_approval\", \n",
    "                   \"discharge_mean\", \"discharge_mean_approval\", \n",
    "                   \"gage_height_max\", \"gage_height_max_approval\", \n",
    "                   \"gage_height_min\", \"gage_height_min-approval\", \n",
    "                   \"gage_height_mean\", \"gage_height_mean_approval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the structure of the dataframe -- R: str(df_USGS))\n",
    "df_USGS.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the dimensions\n",
    "df_USGS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_USGS.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Viewing records in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the head (first 5 records) of the dataset\n",
    "df_USGS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altenatively, view the first 9 records\n",
    "df_USGS.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or 6 records, selected at random\n",
    "df_USGS.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or, the last 3 records\n",
    "df_USGS.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View records 30000 to 30005, columns 3, 8, and 14\n",
    "df_USGS.iloc[29999:30004,[2,7,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data type of the 'datetime' column\n",
    "df_USGS['datetime'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data type of all columns\n",
    "df_USGS.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of all data\n",
    "df_USGS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of a specific column\n",
    "df_USGS['discharge_mean'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIPS AND TRICKS: SPREADSHEETS\n",
    "\n",
    "* Files should be saved as .csv or .txt for easy import into Pandas. Note that complex formatting, including formulas in Excel, are not saved when spreadsheets are converted to comma separated or text formats (i.e., values alone are saved).\n",
    "\n",
    "\n",
    "* The first row is reserved for column headers.\n",
    "\n",
    "\n",
    "* A second, secondary row for column headers (e.g., units) should not be used if data are being imported into R. Incorporate units into the first row column headers if necessary.\n",
    "\n",
    "\n",
    "* Short names are preferred for column headers, to the extent they are informative. Additional information can be stored in comments within Python scripts and/or in README files.\n",
    "\n",
    "\n",
    "* Spaces in column names are allowed in Pandas, but should be replaced with underscores (\"`_`\") to avoid issues. \n",
    "\n",
    "\n",
    "* Avoid symbols in column headers. This can cause issues when importing into Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
